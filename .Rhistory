usethis::create_github_token()
usethis::create_github_token()
install.packages("usethis")
usethis::create_github_token()
gitcreds::gitcreds_set()
git config --global user.email "202112437@alu.comillas.edu"
git config --global user.name "carlosgmv197"
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(haven)
library(nycflights13)
library(gridExtra)
chlstrl=read.csv("./data/cholesterol.csv")
str(chlstrl)
#Esto nos permite saber cuántos valores son NA y cuántos no lo son de la tabla completa
table(is.na(chlstrl))
#Esto nos permite saber la localización de cada valor na en la tabla (con head solo salen las 6 primeras filas)
head(is.na(chlstrl))
summary(chlstrl)
#Recorrido intercuartílico
IQR(chlstrl$chol,na.rm=TRUE)
#Los valores atípicos
unname(quantile(chlstrl$chol,probs=c(1/4, 3/4), na.rm=TRUE) + c(-1,1) * 1.5 * IQR(chlstrl$chol,na.rm=TRUE))
#La desviación estándar
sd(chlstrl$chol, na.rm=TRUE)
#La varianza
var(chlstrl$chol, na.rm=TRUE)
summary(chlstrl$chol)
#En este chunk se realiza el histograma de la variable colesterol, interpretada como continua
cortes=seq(min(chlstrl$chol, na.rm=T),max(chlstrl$chol, na.rm=T), length.out=26)
ggplot(chlstrl, aes(chol)) +
geom_histogram(aes(y=stat(density)),breaks=cortes, fill="orange", color="black") +
geom_density(color="red",size=1.5)
#Aqui se realiza el diagrama boxplot/violín/dispersión de una variable discreta
ggplot(chlstrl)+
geom_violin(mapping = aes(x=0, y=chol))+
geom_boxplot(mapping = aes(y=chol),fill="orange") +
geom_jitter(aes(x=0, y=chol),
position=position_jitter(w=0.05, h=0), col="blue")
summary(chlstrl$gender)
#table(chlstrl$gender)
#prop.table(table(chlstrl$gender))
#Tabulación de géneros según su frecuencia
chlstrl %>%
count(gender)
#Tabulación de géneros según su frecuencia relativa
chlstrl %>%
count(gender) %>%
mutate(gender, relFreq = prop.table(n), n=NULL)
ggplot(chlstrl) +
geom_bar(aes(gender, fill=gender))
#Sustitución de las columnas de peso y altura por sus equivalentes en el sistema métrico
chlstrl=chlstrl %>%
mutate(height=height*0.0254, weight=weight*0.454)
(chlstrl)
#Creación de la columna BMI a partir de peso y altura
chlstrl=chlstrl %>%
mutate(BMI=weight/(height^2))
(chlstrl)
#Clasificación de todas las filas como parte de un grupo de edad determinado en forma de nueva columna
(chlstrl=chlstrl %>%
mutate(ageGroup=cut(age,breaks=c(10,40,70,100))))
#Frecuencia de cada grupo de edad
(chlstrl %>%
count(ageGroup))
#Cálculo de la media del colesterol y BMI por grupos de edad
(chlstrl %>%
filter(gender=='female') %>%
group_by(ageGroup) %>%
summarise(MedChol=mean(chol, na.rm = TRUE), MedBMI=mean(BMI, na.rm=TRUE)))
set.seed(2019)
x = sample(c(-1, 1), 9, replace = TRUE) * sample(1:20, 9, replace = TRUE)
cat(paste0(x, sep=", "))
cambiossigno=function(x=sample(c(-1,1), 9, replace = TRUE) * sample(1:20, 9, replace = TRUE)){
sol=list()
a=length(x)
cs=0
for(y in 1:(a-1)){
if ((x[y]>0)==TRUE && (x[y+1]<0)==TRUE){
cs=cs+1
}else if ((x[y]<0)==TRUE && (x[y+1]>0)==TRUE){
cs=cs+1
}
}
sol$vector=x
sol$cambSigno=cs
returnValue(sol)
}
cambiossigno(x)
cambiossigno()
cat("[1] 3 4 7 8")
cambiossignopos=function(x=sample(c(-1,1), 9, replace = TRUE) * sample(1:20, 9, replace = TRUE)){
sol=list()
a=length(x)
pos=c()
for(y in 1:(a-1)){
if ((x[y]>0)==TRUE && (x[y+1]<0)==TRUE){
pos=append(pos,y+1)
}else if ((x[y]<0)==TRUE && (x[y+1]>0)==TRUE){
pos=append(pos,y+1)
}
}
sol$vector=x
sol$posiciones=pos
returnValue(sol)
}
cambiossignopos(x)
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +
geom_point() +
geom_smooth()
g1=ggplot() +
geom_point(data = mpg, mapping = aes(x = displ, y = hwy)) +
geom_smooth(data = mpg, mapping = aes(x = displ, y = hwy), se=FALSE)
g2=ggplot() +
geom_point(data = mpg, mapping = aes(x = displ, y = hwy)) +
geom_smooth(data = mpg, mapping = aes(x = displ, y = hwy,group=drv), se=FALSE)
g3=ggplot() +
geom_point(data = mpg, mapping = aes(x = displ, y = hwy, color=drv)) +
geom_smooth(data = mpg, mapping = aes(x = displ, y = hwy, color=drv), se=FALSE)
g4=ggplot() +
geom_point(data = mpg, mapping = aes(x = displ, y = hwy, color=drv)) +
geom_smooth(data = mpg, mapping = aes(x = displ, y = hwy), se=FALSE)
g5=ggplot() +
geom_point(data = mpg, mapping = aes(x = displ, y = hwy, color=drv)) +
geom_smooth(data = mpg, mapping = aes(x = displ, y = hwy, linetype=drv), se=FALSE)
g6=ggplot() +
geom_point(data = mpg, mapping = aes(x = displ, y = hwy, fill=drv), shape = 21,color="white",size = 2.5, stroke = 1.5)
grid.arrange(g1,g2,g3,g4,g5,g6,nrow = 3)
flights %>%
filter(arr_delay>=120)
flights %>%
filter(dest=='IAH'| dest=='HOU')
flights %>%
filter(dest %in% c('IAH','HOU'))
flights %>%
filter(carrier=='UA'| carrier=='AA' | carrier=='DL')
flights %>%
filter(carrier %in% c('UA','AA','DL'))
flights %>%
filter(month==7 | month==8 | month==9 )
flights %>%
filter(month %in% c(7:9))
flights %>%
filter(arr_delay >120, dep_delay<=0)
flights %>%
filter(dep_delay >=60,arr_delay<(dep_delay-30))
flights %>%
filter(dep_time==2400 | dep_time<=600)
setwd("C:/MASTERBD/FundamentosMatematicos/GITHUB/garciamaurinno_carlos/A0")
knitr::opts_chunk$set(echo = TRUE)
setwd("C:/MASTERBD/FundamentosMatematicos/GITHUB/Tarea/2")
test=read_csv("./data/datatestResults.csv")
knitr::opts_chunk$set(echo = TRUE)
setwd("C:/MASTERBD/FundamentosMatematicos/GITHUB/Tarea/2")
library(tidyverse)
library(ggplot2)
library(nycflights13)
X1=c(0:3)
pX1=c(64/125,48/125,12/125,1/125)
(tableX1=data.frame(X1,pX1=pX1))
#Media teórica
(mu_t=sum(X1*pX1))
#Varianza teórica
(var_t=sum(((X1-mu_t)^2)*pX1))
set.seed(2021)
k=100000
n=10
mediasMuestral1 = replicate(k, {
muestra = sample(X1, n, replace = TRUE,prob=pX1)
mean(muestra)
})
#Histograma de mediamuestral1 (tamaño 10)
hist(mediasMuestral1, breaks = 20, main="",
col="peachpuff", probability = TRUE, xlim=range(X1))
abline(v = mu_t, lty=2, lwd=5, col="blue")
m=30
mediasMuestral2 = replicate(k, {
muestra = sample(X1, m, replace = TRUE,prob=pX1)
mean(muestra)
})
#Histograma de mediamuestral1 (tamaño 30)
hist(mediasMuestral2, breaks = 20, main="",
col="peachpuff", probability = TRUE, xlim=range(X1))
abline(v = mu_t, lty=2, lwd=5, col="blue")
X2=c(0:2)
pX2=c(1/2,1/4,1/4)
(tableX2=data.frame(X2,pX2))
#Media teórica
(mu_t1=sum(X2*pX2))
#Varianza teórica
(var_t1=sum(((X2-mu_t1)^2)*pX2))
(pos=merge(tableX1$X1,tableX2$X2) %>%
#Valores de la suma X1 +X2 con tabla de probabilidad
mutate(posSum=x+y,prob=rep(tableX1$pX1,times=3)*rep(tableX2$pX2,each=4)))
pos$posSum=as.factor(pos$posSum)
pos %>%
group_by(posSum) %>%
summarise(prob=sum(prob))
#Media teórica de la suma X1 y X2
(mu_t2=sum(as.numeric(paste(pos$posSum))*pos$prob))
set.seed(2021)
k=100000
n1=1
mediasMuestral3 = replicate(k, {
muestraX1 = sample(X1, n1, replace = TRUE,prob=pX1)
muestraX2 = sample(X2, n1, replace = TRUE,prob=pX2)
mean(muestraX1) + mean(muestraX2)
})
#Media con k valores de medias muestrales
(mediaFinal=mean(mediasMuestral3))
test=read_csv("./data/datatestResults.csv")
#Para hacer la lista tidy, se han agrupado las columnas week1, week2... en una columna week que contiene unicamente el numero de la semana en cuestión. Además, se han separado los valores de sexo y edad en columnas diferentes.
testTidy=test %>%
pivot_longer(week1:week5, names_to = 'week') %>%
separate(gender_age, c("gender", "age")) %>%
separate(week,c('x','week'), sep=4) %>%
mutate(x=NULL)
#Aquí se cambian el número de semana y la edad de tipo chr a tipo numérico
testTidy$week=as.numeric(testTidy$week)
testTidy$age=as.numeric(testTidy$age)
testTidy
#Como se puede observar, hay una relacion existente entre el precio y el quilate, ya que, por lo general, a mayor kilate tendriamos un mayor precio.
ggplot(diamonds, aes(x = carat, y = price)) +
geom_point()
#Como se puede ver, el valor de la variable corte no influye en el precio del diamante y no hay tyendencias observables.
ggplot(diamonds, aes(x = cut, y = price)) +
geom_boxplot()
#No hay relación ninguna entre depth y precio, para un valor cualquiera de depth tenemos un rango extremadamente amplio de precios.No hay tendencias observadas.
ggplot(diamonds, aes(x = depth, y = price)) +
geom_point()
#No hay relación ninguna entre table y precio, para un valor cualquiera de table tenemos un rango extremadamente amplio de precios. No hay tendencias observadas.
ggplot(diamonds, aes(x = table, y = price)) +
geom_point()
#Primero ordenamos el color en orden ascendente en el que J es el menos preferible y D el más preferible. Tras esto llegamos a la conclusión de que no hay una relación clara entre precio y color, y solo podemos observar una mayor variabilidad cuanto más nos acercamos a J.
diamonds %>%
mutate(color = fct_rev(color)) %>%
ggplot(aes(x = color, y = price)) +
geom_boxplot()
#No hay relación entre claridad y precio, a destacar está que la variabilidad del precio aumenta en las categorías centrales de la claridad y disminuye hacia ambos extremos.
ggplot(data = diamonds) +
geom_boxplot(mapping = aes(x = clarity, y = price))
#Buscamos correlación entre quilate (que tiene correlación con precio) y corte.Como se puede observar, la variabilidad del corte 'fair' es baja, y su mediana es la mayor de entre todos los cortes. Esto nos lleva a la conclusión de que en un corte 'fair' hay más valores de quilate alto. Como en la tabla quilate vs precio vemos que hay una relación lineal (mayor quilate, mayor precio generalmente), podemos concluir que a menor calidad (corte 'fair'), mayor precio (mayor quilate).
ggplot(diamonds, aes(x = cut, y = carat)) +
geom_boxplot()
who_1=who %>%
pivot_longer(
cols = new_sp_m014:newrel_f65,
names_to = "key",
values_to = "cases",
values_drop_na = TRUE
) %>%
mutate(
key = stringr::str_replace(key, "newrel", "new_rel")
) %>%
separate(key, c("new", "var", "sexage")) %>%
select(-new, -iso2, -iso3) %>%
separate(sexage, c("sex", "age"), sep = 1)
#Aquí generamos una gráfica de números de casos vs tiempo. La gráfica tiene en cuenta el país y el sexo de las personas afectadas. Como se puede ver, esto nos proporciona poca visión del impacto real por país, sobre todo en los más afectados.
who_1 %>%
group_by(country, year, sex) %>%
summarise(cases = sum(cases)) %>%
unite(country_sex, country, sex, remove = FALSE) %>%
ggplot(aes(x = year, y = cases, group = country_sex, colour = sex)) +
geom_line()
#Aquí seleccionamos los países con más casos (>500000)
(CountriesCases=who_1 %>%
group_by(country) %>%
summarise(n=sum(cases)) %>%
filter(n>500000) %>%
select(country))
#Aquí se grafican los casos según el sexo. Además, la separación de tablas dependiendo del país nos permite ver los datos con mucha más claridad.
who_1 %>%
filter(country %in% CountriesCases$country) %>%
group_by(country, year, sex) %>%
summarise(cases = sum(cases)) %>%
unite(country_sex, country, sex, remove=FALSE) %>%
ggplot(aes(x=year, y=cases, group =country_sex, colour=sex)) +
geom_line()+
facet_wrap(~country, scales='free_y')
